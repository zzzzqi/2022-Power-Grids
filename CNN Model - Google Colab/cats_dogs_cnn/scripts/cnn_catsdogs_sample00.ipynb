{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_catsdogs_sample00.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "eBG59ADuhvLn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "VlF4q3J5hw41"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()"
      ],
      "metadata": {
        "id": "tAJ7a8LDh56L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add convolution layer, assuming 32 kernels and size of kernel as 3 * 3\n",
        "# The number of kernels could be customised\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))"
      ],
      "metadata": {
        "id": "W4T0lWBOiV3E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add max pooling layer, assuming size of pool as 2 * 2\n",
        "model.add(layers.MaxPool2D(pool_size=(2, 2)))"
      ],
      "metadata": {
        "id": "Kf4pxskYiuNt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add another set of convolutional layers here, before flattening\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2, 2)))"
      ],
      "metadata": {
        "id": "mhj3jYrli-nv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add flattening, where the output is the input of the ANN\n",
        "model.add(layers.Flatten())"
      ],
      "metadata": {
        "id": "WIRotJPTjUOh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add full connection, where ANN is built with 1 hidden layer and 1 output layer\n",
        "# There are 128 neurons included in the hidden layer\n",
        "model.add(layers.Dense(units=128, activation='relu'))"
      ],
      "metadata": {
        "id": "xBaXFoNRjb12"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add another hidden layer\n",
        "model.add(layers.Dense(units=128, activation='relu'))"
      ],
      "metadata": {
        "id": "fKaJRp6NjuWX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the sigmoid layer\n",
        "model.add(layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "ZIUT-zNjj8BV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure the CNN\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "StrNNecKkDfs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the CNN to the images\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "IRF0PJhAkEz_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)"
      ],
      "metadata": {
        "id": "C1pRg0kTkkm8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable mounting Google Drive locally\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "w6P1xspz2ixc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhTz-0py6tGE",
        "outputId": "fc20bc70-b37e-420e-89d4-61c9d7a56511"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = train_datagen.flow_from_directory('/content/drive/My Drive/cat_dog_dataset/training_set',\n",
        "                                                 target_size=(128, 128),\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode='binary')"
      ],
      "metadata": {
        "id": "JnABe8cv6282",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0e280e6-0858-4af5-93b2-ea1dcb5c60bf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8010 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = test_datagen.flow_from_directory('/content/drive/My Drive/cat_dog_dataset/test_set',\n",
        "                                            target_size=(128, 128),\n",
        "                                            batch_size=32,\n",
        "                                            class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRNR_P_Mb21t",
        "outputId": "a040b901-d8ba-4eb8-897f-a1445b468ed0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(training_set,\n",
        "          epochs=25,\n",
        "          validation_data=test_set,\n",
        "          validation_steps=62.5)"
      ],
      "metadata": {
        "id": "vwZBX4EVcrma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cd61652-fdbf-4066-e34e-3ee798e1b7bc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r251/251 [==============================] - 576s 2s/step - loss: 0.6310 - accuracy: 0.6412 - val_loss: 0.5808 - val_accuracy: 0.6925\n",
            "Epoch 2/25\n",
            "251/251 [==============================] - 208s 828ms/step - loss: 0.5708 - accuracy: 0.7021 - val_loss: 0.5312 - val_accuracy: 0.7330\n",
            "Epoch 3/25\n",
            "251/251 [==============================] - 208s 828ms/step - loss: 0.5347 - accuracy: 0.7295 - val_loss: 0.5387 - val_accuracy: 0.7325\n",
            "Epoch 4/25\n",
            "251/251 [==============================] - 207s 823ms/step - loss: 0.5066 - accuracy: 0.7537 - val_loss: 0.5062 - val_accuracy: 0.7610\n",
            "Epoch 5/25\n",
            "251/251 [==============================] - 206s 818ms/step - loss: 0.4741 - accuracy: 0.7714 - val_loss: 0.4941 - val_accuracy: 0.7650\n",
            "Epoch 6/25\n",
            "251/251 [==============================] - 208s 827ms/step - loss: 0.4505 - accuracy: 0.7853 - val_loss: 0.4840 - val_accuracy: 0.7815\n",
            "Epoch 7/25\n",
            "251/251 [==============================] - 206s 818ms/step - loss: 0.4258 - accuracy: 0.7988 - val_loss: 0.5108 - val_accuracy: 0.7625\n",
            "Epoch 8/25\n",
            "251/251 [==============================] - 206s 820ms/step - loss: 0.3997 - accuracy: 0.8147 - val_loss: 0.4907 - val_accuracy: 0.7830\n",
            "Epoch 9/25\n",
            "251/251 [==============================] - 207s 824ms/step - loss: 0.3903 - accuracy: 0.8218 - val_loss: 0.4799 - val_accuracy: 0.7975\n",
            "Epoch 10/25\n",
            "251/251 [==============================] - 206s 821ms/step - loss: 0.3743 - accuracy: 0.8336 - val_loss: 0.4938 - val_accuracy: 0.7945\n",
            "Epoch 11/25\n",
            "251/251 [==============================] - 210s 835ms/step - loss: 0.3445 - accuracy: 0.8473 - val_loss: 0.4972 - val_accuracy: 0.8025\n",
            "Epoch 12/25\n",
            "251/251 [==============================] - 209s 830ms/step - loss: 0.3323 - accuracy: 0.8561 - val_loss: 0.5176 - val_accuracy: 0.7790\n",
            "Epoch 13/25\n",
            "251/251 [==============================] - 212s 843ms/step - loss: 0.3050 - accuracy: 0.8657 - val_loss: 0.5315 - val_accuracy: 0.7715\n",
            "Epoch 14/25\n",
            "251/251 [==============================] - 211s 841ms/step - loss: 0.2947 - accuracy: 0.8740 - val_loss: 0.5157 - val_accuracy: 0.7885\n",
            "Epoch 15/25\n",
            "251/251 [==============================] - 210s 836ms/step - loss: 0.2733 - accuracy: 0.8839 - val_loss: 0.5230 - val_accuracy: 0.7885\n",
            "Epoch 16/25\n",
            "251/251 [==============================] - 211s 838ms/step - loss: 0.2581 - accuracy: 0.8920 - val_loss: 0.5182 - val_accuracy: 0.7910\n",
            "Epoch 17/25\n",
            "251/251 [==============================] - 209s 831ms/step - loss: 0.2384 - accuracy: 0.9030 - val_loss: 0.5681 - val_accuracy: 0.7860\n",
            "Epoch 18/25\n",
            "251/251 [==============================] - 210s 837ms/step - loss: 0.2277 - accuracy: 0.9065 - val_loss: 0.5766 - val_accuracy: 0.8035\n",
            "Epoch 19/25\n",
            "251/251 [==============================] - 210s 835ms/step - loss: 0.2257 - accuracy: 0.9100 - val_loss: 0.5471 - val_accuracy: 0.7955\n",
            "Epoch 20/25\n",
            "251/251 [==============================] - 207s 825ms/step - loss: 0.2076 - accuracy: 0.9210 - val_loss: 0.6213 - val_accuracy: 0.7885\n",
            "Epoch 21/25\n",
            "251/251 [==============================] - 208s 828ms/step - loss: 0.1951 - accuracy: 0.9221 - val_loss: 0.6046 - val_accuracy: 0.8015\n",
            "Epoch 22/25\n",
            "251/251 [==============================] - 207s 824ms/step - loss: 0.1879 - accuracy: 0.9252 - val_loss: 0.6329 - val_accuracy: 0.7905\n",
            "Epoch 23/25\n",
            "251/251 [==============================] - 209s 831ms/step - loss: 0.1781 - accuracy: 0.9277 - val_loss: 0.6446 - val_accuracy: 0.7965\n",
            "Epoch 24/25\n",
            "251/251 [==============================] - 209s 831ms/step - loss: 0.1690 - accuracy: 0.9308 - val_loss: 0.6819 - val_accuracy: 0.8040\n",
            "Epoch 25/25\n",
            "251/251 [==============================] - 209s 832ms/step - loss: 0.1560 - accuracy: 0.9388 - val_loss: 0.6765 - val_accuracy: 0.7865\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb1e3810090>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/cnn_catsdogs_sample00_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ7SEEMyYBK7",
        "outputId": "70722c09-a62c-47a8-fdd0-70629f94df21"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/cnn_catsdogs_sample00_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/cnn_catsdogs_sample00_model.h5')"
      ],
      "metadata": {
        "id": "x8wQkKh_YPSy"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JmOc7W5bYdmq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}